{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f150f582-8633-4464-80c0-37cc1c7fa317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/22 10:02:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python3.10/dist-packages\")  \n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark/spark-3.5.4-bin-hadoop3\")  # Path to your Spark installation\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Yield Prediction\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed9ab939-5547-49e4-a61c-2d4e6dad4312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+----+-----------+-----------------------------+-----------------+--------+\n",
      "|s_no|   Area|       Item|Year|hg/ha_yield|average_rain_fall_mm_per_year|pesticides_tonnes|avg_temp|\n",
      "+----+-------+-----------+----+-----------+-----------------------------+-----------------+--------+\n",
      "|   0|Albania|      Maize|1990|      36613|                       1485.0|            121.0|   16.37|\n",
      "|   1|Albania|   Potatoes|1990|      66667|                       1485.0|            121.0|   16.37|\n",
      "|   2|Albania|Rice, paddy|1990|      23333|                       1485.0|            121.0|   16.37|\n",
      "|   3|Albania|    Sorghum|1990|      12500|                       1485.0|            121.0|   16.37|\n",
      "|   4|Albania|   Soybeans|1990|       7000|                       1485.0|            121.0|   16.37|\n",
      "|   5|Albania|      Wheat|1990|      30197|                       1485.0|            121.0|   16.37|\n",
      "|   6|Albania|      Maize|1991|      29068|                       1485.0|            121.0|   15.36|\n",
      "|   7|Albania|   Potatoes|1991|      77818|                       1485.0|            121.0|   15.36|\n",
      "|   8|Albania|Rice, paddy|1991|      28538|                       1485.0|            121.0|   15.36|\n",
      "|   9|Albania|    Sorghum|1991|       6667|                       1485.0|            121.0|   15.36|\n",
      "|  10|Albania|   Soybeans|1991|       6066|                       1485.0|            121.0|   15.36|\n",
      "|  11|Albania|      Wheat|1991|      20698|                       1485.0|            121.0|   15.36|\n",
      "|  12|Albania|      Maize|1992|      24876|                       1485.0|            121.0|   16.06|\n",
      "|  13|Albania|   Potatoes|1992|      82920|                       1485.0|            121.0|   16.06|\n",
      "|  14|Albania|Rice, paddy|1992|      40000|                       1485.0|            121.0|   16.06|\n",
      "|  15|Albania|    Sorghum|1992|       3747|                       1485.0|            121.0|   16.06|\n",
      "|  16|Albania|   Soybeans|1992|       4507|                       1485.0|            121.0|   16.06|\n",
      "|  17|Albania|      Wheat|1992|      24388|                       1485.0|            121.0|   16.06|\n",
      "|  18|Albania|      Maize|1993|      24185|                       1485.0|            121.0|   16.05|\n",
      "|  19|Albania|   Potatoes|1993|      98446|                       1485.0|            121.0|   16.05|\n",
      "+----+-------+-----------+----+-----------+-----------------------------+-----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"./yield_df.csv\", header=True, inferSchema=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0915ea0-8b5e-42aa-8e33-5606269c8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7aefe39-1617-4fa3-98ae-6e2c5a8e2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the data (index, encode, assemble)\n",
    "area_indexer = StringIndexer(inputCol=\"Area\", outputCol=\"Area_indexed\").fit(data)\n",
    "\n",
    "\n",
    "item_indexer = StringIndexer(inputCol=\"Item\", outputCol=\"Item_indexed\").fit(data)\n",
    "\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[\"Area_indexed\", \"Item_indexed\"], \n",
    "                        outputCols=[\"Area_encoded\", \"Item_encoded\"])\n",
    "\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Area_encoded\", \"Item_encoded\", \"average_rain_fall_mm_per_year\", \n",
    "               \"pesticides_tonnes\", \"avg_temp\"], \n",
    "    outputCol=\"features\")\n",
    "\n",
    "\n",
    "\n",
    "# Create pipeline and transform data\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[area_indexer, item_indexer, encoder, assembler])\n",
    "prepared_data = pipeline.fit(data).transform(data)\n",
    "\n",
    "# Split into training and test sets\n",
    "train_data, test_data = prepared_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34041206-4338-4981-9caa-9e1b52aaedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- s_no: integer (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- hg/ha_yield: integer (nullable = true)\n",
      " |-- average_rain_fall_mm_per_year: double (nullable = true)\n",
      " |-- pesticides_tonnes: double (nullable = true)\n",
      " |-- avg_temp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8fc00b9-9fc8-441e-8a41-23d661fc063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "#lr = LinearRegression(featuresCol=\"features\", labelCol=\"hg/ha_yield\")\n",
    "\n",
    "#model = lr.fit(train_data)\n",
    "\n",
    "#predictions = model.transform(test_data)\n",
    "#predictions.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efd27c26-c707-4558-80be-29d5425d2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 42503.12, R2 = 0.75\n",
      "+----+-------+--------+----+-----------+-----------------------------+-----------------+--------+------------+------------+----------------+-------------+--------------------+------------------+\n",
      "|s_no|   Area|    Item|Year|hg/ha_yield|average_rain_fall_mm_per_year|pesticides_tonnes|avg_temp|Area_indexed|Item_indexed|    Area_encoded| Item_encoded|            features|        prediction|\n",
      "+----+-------+--------+----+-----------+-----------------------------+-----------------+--------+------------+------------+----------------+-------------+--------------------+------------------+\n",
      "|   6|Albania|   Maize|1991|      29068|                       1485.0|            121.0|   15.36|        71.0|         1.0|(100,[71],[1.0])|(9,[1],[1.0])|(112,[71,101,109,...| 27541.69234901284|\n",
      "|  19|Albania|Potatoes|1993|      98446|                       1485.0|            121.0|   16.05|        71.0|         0.0|(100,[71],[1.0])|(9,[0],[1.0])|(112,[71,100,109,...|  185511.513747724|\n",
      "|  21|Albania|Soybeans|1993|       7998|                       1485.0|            121.0|   16.05|        71.0|         4.0|(100,[71],[1.0])|(9,[4],[1.0])|(112,[71,104,109,...| 5849.060531453477|\n",
      "|  31|Albania|   Maize|1996|      32604|                       1485.0|           313.96|   15.64|        71.0|         1.0|(100,[71],[1.0])|(9,[1],[1.0])|(112,[71,101,109,...|27686.603253193403|\n",
      "|  37|Albania|Soybeans|1997|      12768|                       1485.0|           376.93|    15.9|        71.0|         4.0|(100,[71],[1.0])|(9,[4],[1.0])|(112,[71,104,109,...| 5803.166562049184|\n",
      "+----+-------+--------+----+-----------+-----------------------------+-----------------+--------+------------+------------+----------------+-------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"hg/ha_yield\", regParam=0.1)\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"hg/ha_yield\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "lr_rmse = lr_evaluator.evaluate(lr_predictions)\n",
    "lr_r2 = lr_evaluator.setMetricName(\"r2\").evaluate(lr_predictions)\n",
    "\n",
    "print(f\"Linear Regression: RMSE = {lr_rmse:.2f}, R2 = {lr_r2:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "lr_predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32332e53-ad87-4fb0-9a0b-1b263cf67e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: RMSE = 40047.70, R2 = 0.78\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"hg/ha_yield\", maxBins=128)\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"hg/ha_yield\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "dt_rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "dt_r2 = dt_evaluator.setMetricName(\"r2\").evaluate(dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree: RMSE = {dt_rmse:.2f}, R2 = {dt_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6405cb2-9702-4705-8128-2f3fbbac1911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: RMSE = 44487.19, R2 = 0.72\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"hg/ha_yield\", maxBins=128, numTrees=50)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "rf_evaluator = RegressionEvaluator(labelCol=\"hg/ha_yield\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rf_rmse = rf_evaluator.evaluate(rf_predictions)\n",
    "rf_r2 = rf_evaluator.setMetricName(\"r2\").evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Random Forest: RMSE = {rf_rmse:.2f}, R2 = {rf_r2:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f6068-b178-47dd-b0e7-f7976667f818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
