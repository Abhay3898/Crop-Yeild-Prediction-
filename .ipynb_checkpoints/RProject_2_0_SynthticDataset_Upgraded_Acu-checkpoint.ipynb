{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04d8222-8a13-4c00-a634-0b758650b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/abhay/Spark_dir/myenv/lib/python3.10/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd71fba6-e85c-4a85-b00d-7dc4837dcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python3.10/dist-packages\")  \n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark/spark-3.5.4-bin-hadoop3\")  # Path to your Spark installation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5777719e-b14a-44eb-b519-977a6736003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 13:36:25 WARN Utils: Your hostname, abhay-ki-bandi resolves to a loopback address: 127.0.1.1; using 192.168.163.114 instead (on interface wlp0s20f3)\n",
      "25/01/21 13:36:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/21 13:36:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/21 13:36:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/01/21 13:36:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Model Comparison\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd863a3c-6cca-48b4-a5fb-50d1a8a9b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|   Region|Crop Type|Rainfall (mm)|Temperature (°C)|Soil pH|Nitrogen (ppm)|Sowing Date|Harvest Date|Yield (tons/ha)|Soil Type|\n",
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|  Haryana|    Maize|        422.7|            22.0|    5.8|          22.3| 2023-03-11|  2023-11-13|            2.2|     Clay|\n",
      "|  Haryana|     Rice|        394.9|            23.5|    7.0|          54.9| 2023-02-05|  2023-09-08|            3.6|    Loamy|\n",
      "|  Haryana|    Wheat|        306.7|            29.8|    7.0|          54.4| 2023-01-07|  2023-08-19|            2.7|    Sandy|\n",
      "|   Punjab|    Wheat|        592.3|            34.9|    6.5|          58.0| 2023-05-18|  2023-10-19|            3.7|     Clay|\n",
      "|   Punjab|     Rice|        653.2|            22.7|    6.3|          24.7| 2023-05-23|  2023-12-09|            3.6|    Sandy|\n",
      "|Rajasthan|     Rice|        449.2|            17.4|    5.6|          30.8| 2023-05-11|  2023-07-26|            3.3|     Clay|\n",
      "|  Haryana|     Rice|        592.8|            35.0|    6.2|          20.3| 2023-06-02|  2023-11-11|            4.2|    Loamy|\n",
      "|Rajasthan|    Wheat|        340.9|            29.2|    6.2|          28.5| 2023-04-10|  2023-10-20|            5.3|     Clay|\n",
      "|  Haryana|     Rice|        604.6|            33.2|    5.9|          52.2| 2023-06-25|  2023-12-21|            5.0|    Sandy|\n",
      "|  Haryana|     Rice|        480.6|            32.9|    6.5|          30.0| 2023-04-06|  2023-10-01|            5.0|    Loamy|\n",
      "|Rajasthan|    Maize|        592.4|            23.6|    7.1|          49.6| 2023-05-26|  2023-10-05|            4.8|     Clay|\n",
      "|  Haryana|     Rice|        690.4|            28.7|    6.8|          41.4| 2023-02-13|  2023-08-17|            3.3|    Loamy|\n",
      "|Rajasthan|     Rice|        277.4|            34.7|    6.6|          30.3| 2023-02-09|  2023-09-23|            1.8|     Clay|\n",
      "|   Punjab|    Maize|        562.6|            25.7|    5.5|          47.5| 2023-05-12|  2023-09-28|            1.6|    Sandy|\n",
      "|Rajasthan|    Wheat|        467.6|            30.1|    6.4|          43.5| 2023-06-08|  2023-08-09|            3.4|     Clay|\n",
      "|Rajasthan|    Maize|        667.9|            25.1|    7.1|          52.5| 2023-04-01|  2023-12-28|            1.5|    Sandy|\n",
      "|  Haryana|    Maize|        779.9|            34.0|    6.2|          28.0| 2023-03-09|  2023-10-21|            3.0|    Loamy|\n",
      "|  Haryana|    Maize|        563.5|            15.0|    7.1|          25.9| 2023-05-05|  2023-12-01|            5.1|    Sandy|\n",
      "|  Haryana|    Maize|        688.9|            32.1|    7.2|          39.8| 2023-05-13|  2023-12-24|            1.9|     Clay|\n",
      "|  Haryana|     Rice|        394.3|            20.8|    7.1|          22.8| 2023-06-12|  2023-09-17|            2.0|     Clay|\n",
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = spark.read.csv(\"./synthetic_crop_yield_dataset.csv\", header=True, inferSchema=True)\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6fac03-584e-4444-89f6-43a0e20437ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "state_indexer = StringIndexer(inputCol=\"Region\", outputCol=\"state_index\")\n",
    "data = state_indexer.fit(data).transform(data)\n",
    "\n",
    "crop_indexer = StringIndexer(inputCol=\"Crop Type\", outputCol=\"crop_index\")\n",
    "data = crop_indexer.fit(data).transform(data)\n",
    "\n",
    "soil_indexer = StringIndexer(inputCol=\"Soil Type\", outputCol=\"soil_index\")\n",
    "data = soil_indexer.fit(data).transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11400fb5-b135-4982-8ad9-a8c5d962059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, floor\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Convert label column to integer by flooring values (or round/mapping)\n",
    "\n",
    "# Ensure indices are integers\n",
    "data = data.withColumn(\"state_index\", floor(col(\"state_index\")))\n",
    "data = data.withColumn(\"crop_index\", floor(col(\"crop_index\")))\n",
    "data = data.withColumn(\"soil_index\", floor(col(\"soil_index\")))\n",
    "\n",
    "#data = data.withColumn(\"label\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d701ddf-ddbf-492b-a4b8-85344666c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_columns = [\"state_index\", \"crop_index\", \"Rainfall (mm)\", \"Temperature (°C)\", \"Soil pH\", \"Nitrogen (ppm)\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(data).select(\"features\", \"Yield (tons/ha)\")\n",
    "\n",
    "data = data.withColumn(\"Yield (tons/ha)\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n",
    "#data = data.withColumn(\"features\", col(\"features\").cast(IntegerType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b203fd8-21d4-419a-bd90-d8802c2dfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Yield (tons/ha): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848ec024-9389-42f7-8880-33fc1a26117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312b1056-645a-4cfd-98ef-8778101a5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "#evaluator = MulticlassClassificationEvaluator(\n",
    " #   labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a1ab5d-3163-4f31-a4a1-36a8a846f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,0.0,277.4,34...|\n",
      "|[1.0,2.0,563.5,15...|\n",
      "|[2.0,0.0,674.8,24...|\n",
      "|[1.0,2.0,779.9,34...|\n",
      "|[1.0,0.0,231.3,26...|\n",
      "|[2.0,0.0,657.4,34...|\n",
      "|[2.0,0.0,244.9,29...|\n",
      "|[0.0,1.0,261.0,25...|\n",
      "|[0.0,2.0,667.9,25...|\n",
      "|[2.0,1.0,763.3,33...|\n",
      "|[0.0,2.0,358.2,31...|\n",
      "|[0.0,0.0,435.7,33...|\n",
      "|[0.0,0.0,610.5,34...|\n",
      "|[1.0,0.0,604.7,15...|\n",
      "|[1.0,1.0,440.8,26...|\n",
      "|[2.0,1.0,401.3,20...|\n",
      "|[0.0,0.0,449.2,17...|\n",
      "|[0.0,1.0,586.6,20...|\n",
      "|[1.0,0.0,394.3,20...|\n",
      "|[1.0,2.0,372.4,17...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+\n",
      "|Yield (tons/ha)|\n",
      "+---------------+\n",
      "|              1|\n",
      "|              3|\n",
      "|              5|\n",
      "|              4|\n",
      "|              2|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select(\"features\").distinct().show()\n",
    "test_data.select(\"Yield (tons/ha)\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54717e9c-aa59-417b-9381-71932ac70e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#lr = LogisticRegression(featuresCol='features', labelCol='Yield (tons/ha)')  # Replace 'your_target_column' with your actual label column\n",
    "\n",
    "\n",
    "#model = lr.fit(train_data)\n",
    "\n",
    "#predictions = model.transform(test_data)\n",
    "\n",
    "\n",
    "#predictions.show()\n",
    "\n",
    "\n",
    "#from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "#rmse = evaluator.evaluate(predictions)\n",
    "#print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1d6e52-96aa-47fd-a1b5-3b8ac5f4238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,318.9,17...|              1|[-20.212949007303...|[4.31785408491820...|       2.0|\n",
      "|[0.0,0.0,503.7,31...|              3|[-18.698850157816...|[2.57602318715272...|       3.0|\n",
      "|[0.0,0.0,581.3,19...|              2|[-18.862777432167...|[2.08997963105298...|       3.0|\n",
      "|[0.0,1.0,207.6,29...|              4|[-19.661360848696...|[8.42557102746699...|       2.0|\n",
      "|[0.0,1.0,430.1,25...|              4|[-19.060890117291...|[1.67883559163286...|       2.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.5718104959867516\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,318.9,17...|              1|[0.0,2.1881313131...|[0.0,0.1094065656...|       3.0|\n",
      "|[0.0,0.0,503.7,31...|              3|[0.0,6.8921568627...|[0.0,0.3446078431...|       1.0|\n",
      "|[0.0,0.0,581.3,19...|              2|[0.0,2.8458902208...|[0.0,0.1422945110...|       2.0|\n",
      "|[0.0,1.0,207.6,29...|              4|[0.0,3.3662121212...|[0.0,0.1683106060...|       2.0|\n",
      "|[0.0,1.0,430.1,25...|              4|[0.0,0.7316045066...|[0.0,0.0365802253...|       2.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.533929977694741\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,318.9,17...|              1|[0.0,1.0,1.0,0.0,...|[0.0,0.5,0.5,0.0,...|       1.0|\n",
      "|[0.0,0.0,503.7,31...|              3|[0.0,1.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[0.0,0.0,581.3,19...|              2|[0.0,2.0,5.0,2.0,...|[0.0,0.2,0.5,0.2,...|       2.0|\n",
      "|[0.0,1.0,207.6,29...|              4|[0.0,0.0,5.0,6.0,...|[0.0,0.0,0.384615...|       3.0|\n",
      "|[0.0,1.0,430.1,25...|              4|[0.0,0.0,5.0,6.0,...|[0.0,0.0,0.384615...|       3.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.697749375254331\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    trained_model = model.fit(train_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = trained_model.transform(test_data)\n",
    "    predictions.show(5)\n",
    "    # Evaluate accuracy\n",
    "    \n",
    "\n",
    "    #evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n",
    "    #accuracy = evaluator.evaluate(predictions)\n",
    "    #results[name] = accuracy\n",
    "    #print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "86d879fe-c68f-4ec6-98cb-0604d15df201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "Decision Tree: 0.29\n",
      "Logistic Regression: 0.24\n",
      "Random Forest: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Sort results\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for name, accuracy in sorted_results:\n",
    "    print(f\"{name}: {accuracy:.2f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7dc3-f71d-4c9a-8823-41e503a94a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5909ca-d2bc-4541-a408-39e53b4bd605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
