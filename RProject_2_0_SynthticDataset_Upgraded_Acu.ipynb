{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04d8222-8a13-4c00-a634-0b758650b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/abhay/Spark_dir/myenv/lib/python3.10/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd71fba6-e85c-4a85-b00d-7dc4837dcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python3.10/dist-packages\")  \n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark/spark-3.5.4-bin-hadoop3\")  # Path to your Spark installation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5777719e-b14a-44eb-b519-977a6736003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Model Comparison\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd863a3c-6cca-48b4-a5fb-50d1a8a9b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|    Region|Crop Type|Rainfall (mm)|Temperature (°C)|Soil pH|Nitrogen (ppm)|Sowing Date|Harvest Date|Yield (tons/ha)|Soil Type|\n",
      "+----------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|   Solapur|    Maize|        641.5|            25.9|    5.7|          30.6| 2023-07-08|  2023-11-30|           2.38|    Sandy|\n",
      "|     Latur|    Wheat|        621.3|            31.7|    7.3|          50.2| 2023-01-03|  2023-06-11|           4.79|    Loamy|\n",
      "|    Satara|    Wheat|       1037.4|            22.1|    5.8|          36.9| 2023-06-03|  2023-10-19|           3.62|     Clay|\n",
      "|    Satara|     Toor|        731.3|            23.3|    7.4|          58.6| 2023-07-13|  2023-10-14|           3.53|     Clay|\n",
      "|    Satara|    Bajra|       1040.6|            28.7|    6.2|          56.9| 2023-12-24|  2024-05-25|           4.73|    Sandy|\n",
      "|    Nashik|     Rice|        973.3|            32.1|    7.0|          66.3| 2023-06-04|  2023-09-21|           4.66|     Clay|\n",
      "|  Amravati|    Bajra|        771.3|            31.0|    5.7|          45.6| 2023-12-05|  2024-03-05|            2.5|    Sandy|\n",
      "|    Nagpur|    Bajra|        948.8|            27.8|    6.5|          56.9| 2023-12-16|  2024-04-25|           2.75|    Sandy|\n",
      "|Aurangabad|     Rice|       1265.6|            28.4|    5.7|          35.0| 2023-02-25|  2023-07-01|            3.3|     Clay|\n",
      "| Ratnagiri|    Bajra|        792.1|            26.4|    5.6|          63.5| 2023-06-03|  2023-10-30|           3.45|    Loamy|\n",
      "|  Kolhapur|    Jowar|        812.6|            25.2|    7.1|          51.1| 2023-11-23|  2024-03-19|           5.33|    Loamy|\n",
      "|Aurangabad|    Jowar|       1088.7|            22.3|    6.2|          41.6| 2023-05-03|  2023-08-09|           4.09|    Loamy|\n",
      "|    Nagpur|     Toor|        899.8|            27.7|    6.9|          57.2| 2023-01-18|  2023-04-20|           2.09|    Loamy|\n",
      "|   Solapur|    Bajra|        462.7|            32.6|    6.7|          50.4| 2023-02-08|  2023-06-26|           3.99|    Loamy|\n",
      "|Aurangabad|    Bajra|        674.3|            20.9|    6.6|          51.5| 2023-12-09|  2024-04-24|            3.6|    Sandy|\n",
      "|Aurangabad|     Rice|       1086.7|            31.8|    5.9|          34.9| 2023-06-04|  2023-10-29|           5.11| Laterite|\n",
      "|      Pune|    Jowar|        969.9|            30.3|    6.4|          65.6| 2023-08-08|  2023-12-12|            4.9|    Loamy|\n",
      "|  Amravati|    Maize|        968.3|            31.1|    6.0|          40.0| 2023-05-15|  2023-09-28|           2.66|    Loamy|\n",
      "|     Latur|    Jowar|        504.5|            26.5|    6.1|          32.9| 2023-05-06|  2023-08-07|           5.38|    Loamy|\n",
      "|  Kolhapur|    Maize|        431.7|            27.4|    6.4|          60.3| 2023-07-06|  2023-12-05|           4.94|    Loamy|\n",
      "+----------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = spark.read.csv(\"./Synthetic_Crops_dataset.csv\", header=True, inferSchema=True)\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc6fac03-584e-4444-89f6-43a0e20437ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "state_indexer = StringIndexer(inputCol=\"Region\", outputCol=\"state_index\")\n",
    "data = state_indexer.fit(data).transform(data)\n",
    "\n",
    "crop_indexer = StringIndexer(inputCol=\"Crop Type\", outputCol=\"crop_index\")\n",
    "data = crop_indexer.fit(data).transform(data)\n",
    "\n",
    "soil_indexer = StringIndexer(inputCol=\"Soil Type\", outputCol=\"soil_index\")\n",
    "data = soil_indexer.fit(data).transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11400fb5-b135-4982-8ad9-a8c5d962059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, floor\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Convert label column to integer by flooring values (or round/mapping)\n",
    "\n",
    "# Ensure indices are integers\n",
    "data = data.withColumn(\"state_index\", floor(col(\"state_index\")))\n",
    "data = data.withColumn(\"crop_index\", floor(col(\"crop_index\")))\n",
    "data = data.withColumn(\"soil_index\", floor(col(\"soil_index\")))\n",
    "\n",
    "#data = data.withColumn(\"label\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d701ddf-ddbf-492b-a4b8-85344666c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_columns = [\"state_index\", \"crop_index\", \"Rainfall (mm)\", \"Temperature (°C)\", \"Soil pH\", \"Nitrogen (ppm)\", \"soil_index\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(data).select(\"features\", \"Yield (tons/ha)\")\n",
    "\n",
    "data = data.withColumn(\"Yield (tons/ha)\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n",
    "#data = data.withColumn(\"features\", col(\"features\").cast(IntegerType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b203fd8-21d4-419a-bd90-d8802c2dfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Yield (tons/ha): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "848ec024-9389-42f7-8880-33fc1a26117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "312b1056-645a-4cfd-98ef-8778101a5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8a1ab5d-3163-4f31-a4a1-36a8a846f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[5.0,0.0,757.0,29...|\n",
      "|[5.0,1.0,1082.7,3...|\n",
      "|[5.0,2.0,1327.5,2...|\n",
      "|[8.0,5.0,402.2,23...|\n",
      "|[0.0,5.0,810.8,31...|\n",
      "|[1.0,6.0,999.0,27...|\n",
      "|[2.0,4.0,621.7,20...|\n",
      "|[6.0,1.0,639.9,22...|\n",
      "|[6.0,4.0,1068.9,3...|\n",
      "|[7.0,3.0,438.4,28...|\n",
      "|[9.0,3.0,659.4,24...|\n",
      "|[0.0,1.0,635.4,23...|\n",
      "|[1.0,1.0,921.9,22...|\n",
      "|[1.0,0.0,730.7,32...|\n",
      "|[2.0,4.0,699.8,22...|\n",
      "|[5.0,6.0,859.2,27...|\n",
      "|[7.0,0.0,893.3,24...|\n",
      "|[7.0,2.0,1341.3,2...|\n",
      "|[7.0,4.0,974.1,26...|\n",
      "|[0.0,0.0,716.7,21...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+\n",
      "|Yield (tons/ha)|\n",
      "+---------------+\n",
      "|              4|\n",
      "|              2|\n",
      "|              2|\n",
      "|              3|\n",
      "|              4|\n",
      "|              4|\n",
      "|              5|\n",
      "|              2|\n",
      "|              2|\n",
      "|              2|\n",
      "|              2|\n",
      "|              4|\n",
      "|              2|\n",
      "|              2|\n",
      "|              2|\n",
      "|              4|\n",
      "|              2|\n",
      "|              4|\n",
      "|              5|\n",
      "|              4|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select(\"features\").distinct().show()\n",
    "test_data.select(\"Yield (tons/ha)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54717e9c-aa59-417b-9381-71932ac70e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------------------+\n",
      "|            features|Yield (tons/ha)|        prediction|\n",
      "+--------------------+---------------+------------------+\n",
      "|[0.0,0.0,680.6,22...|              4| 3.169499446086983|\n",
      "|[0.0,0.0,838.7,23...|              2| 3.170009948709631|\n",
      "|[0.0,0.0,1034.1,3...|              2| 3.294024933967022|\n",
      "|[0.0,1.0,500.8,29...|              3|3.2395811976224955|\n",
      "|[0.0,1.0,758.8,21...|              4| 3.335875011060582|\n",
      "|[0.0,1.0,877.7,24...|              4|3.0989124214035937|\n",
      "|[0.0,1.0,1019.0,2...|              5|3.2180977718038326|\n",
      "|[0.0,2.0,1023.3,3...|              2| 3.034293577645074|\n",
      "|[0.0,3.0,400.9,24...|              2|3.6855029378213358|\n",
      "|[0.0,3.0,406.8,28...|              2| 3.312517742097809|\n",
      "|[0.0,3.0,421.6,24...|              2|  3.63421986854299|\n",
      "|[0.0,3.0,531.9,28...|              4|3.2866768448835635|\n",
      "|[0.0,3.0,569.1,26...|              2|3.3241325344555728|\n",
      "|[0.0,3.0,600.5,29...|              2|3.2291498458381946|\n",
      "|[0.0,3.0,870.3,25...|              2| 3.288775591790924|\n",
      "|[0.0,4.0,609.4,22...|              4|3.4137815644309484|\n",
      "|[0.0,5.0,423.7,24...|              2|3.6130603787485667|\n",
      "|[0.0,6.0,557.7,20...|              4|3.6890029287776462|\n",
      "|[0.0,6.0,933.1,33...|              5| 3.474518361432312|\n",
      "|[1.0,0.0,515.2,35...|              4| 3.374848954029242|\n",
      "+--------------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Model saved successfully at /home/abhay/Spark_dir/Research_Project/models/random_forest_model\n",
      "Root Mean Squared Error (RMSE) on test data: 1.072036614669055\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='Yield (tons/ha)')\n",
    "\n",
    "# Train the model\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "predictions.show()\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"/home/abhay/Spark_dir/Research_Project/models/random_forest_model\"\n",
    "model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved successfully at {model_path}\")\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1d6e52-96aa-47fd-a1b5-3b8ac5f4238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,680.6,22...|              4|[-15.192059039953...|[2.95179166203231...|       2.0|\n",
      "|[0.0,0.0,838.7,23...|              2|[-14.992491048902...|[3.92212200795026...|       2.0|\n",
      "|[0.0,0.0,1034.1,3...|              2|[-14.859890398693...|[4.81972421271956...|       2.0|\n",
      "|[0.0,1.0,500.8,29...|              3|[-15.608509220501...|[1.61152520045685...|       2.0|\n",
      "|[0.0,1.0,758.8,21...|              4|[-15.022829330871...|[3.83011072462622...|       2.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.3263707095903692\n",
      "Logistic Regression Accuracy: 0.30\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,680.6,22...|              4|[0.0,0.0,8.466216...|[0.0,0.0,0.423310...|       2.0|\n",
      "|[0.0,0.0,838.7,23...|              2|[0.0,0.0,5.842070...|[0.0,0.0,0.292103...|       2.0|\n",
      "|[0.0,0.0,1034.1,3...|              2|[0.0,0.0,6.096831...|[0.0,0.0,0.304841...|       3.0|\n",
      "|[0.0,1.0,500.8,29...|              3|[0.0,0.0,7.732672...|[0.0,0.0,0.386633...|       2.0|\n",
      "|[0.0,1.0,758.8,21...|              4|[0.0,0.0,6.958398...|[0.0,0.0,0.347919...|       2.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.2789849370245931\n",
      "Random Forest Accuracy: 0.28\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|Yield (tons/ha)|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,680.6,22...|              4|[0.0,0.0,3.0,0.0,...|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "|[0.0,0.0,838.7,23...|              2|[0.0,0.0,7.0,21.0...|[0.0,0.0,0.170731...|       3.0|\n",
      "|[0.0,0.0,1034.1,3...|              2|[0.0,0.0,27.0,33....|[0.0,0.0,0.245454...|       4.0|\n",
      "|[0.0,1.0,500.8,29...|              3|[0.0,0.0,27.0,7.0...|[0.0,0.0,0.551020...|       2.0|\n",
      "|[0.0,1.0,758.8,21...|              4|[0.0,0.0,7.0,21.0...|[0.0,0.0,0.170731...|       3.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.523478800089121\n",
      "Decision Tree Accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "# # Train and evaluate models\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# evaluator2 = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# results = {}\n",
    "# for name, model in models.items():\n",
    "#     # Train the model\n",
    "#     trained_model = model.fit(train_data)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = trained_model.transform(test_data)\n",
    "#     predictions.show(5)\n",
    "#     # Evaluate accuracy\n",
    "    \n",
    "\n",
    "#     #evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "#     rmse = evaluator2.evaluate(predictions)\n",
    "#     print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n",
    "#     accuracy = evaluator.evaluate(predictions)\n",
    "#     results[name] = accuracy\n",
    "#     print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86d879fe-c68f-4ec6-98cb-0604d15df201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print(\"\\nModel Performance Comparison:\")\n",
    "# for name, accuracy in sorted_results:\n",
    "#     print(f\"{name}: {accuracy:.2f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7dc3-f71d-4c9a-8823-41e503a94a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5909ca-d2bc-4541-a408-39e53b4bd605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
