{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04d8222-8a13-4c00-a634-0b758650b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/abhay/Spark_dir/myenv/lib/python3.10/site-packages (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd71fba6-e85c-4a85-b00d-7dc4837dcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python3.10/dist-packages\")  \n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark/spark-3.5.4-bin-hadoop3\")  # Path to your Spark installation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5777719e-b14a-44eb-b519-977a6736003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Model Comparison\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd863a3c-6cca-48b4-a5fb-50d1a8a9b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|   Region|Crop Type|Rainfall (mm)|Temperature (°C)|Soil pH|Nitrogen (ppm)|Sowing Date|Harvest Date|Yield (tons/ha)|Soil Type|\n",
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "|  Haryana|    Maize|        422.7|            22.0|    5.8|          22.3| 2023-03-11|  2023-11-13|            2.2|     Clay|\n",
      "|  Haryana|     Rice|        394.9|            23.5|    7.0|          54.9| 2023-02-05|  2023-09-08|            3.6|    Loamy|\n",
      "|  Haryana|    Wheat|        306.7|            29.8|    7.0|          54.4| 2023-01-07|  2023-08-19|            2.7|    Sandy|\n",
      "|   Punjab|    Wheat|        592.3|            34.9|    6.5|          58.0| 2023-05-18|  2023-10-19|            3.7|     Clay|\n",
      "|   Punjab|     Rice|        653.2|            22.7|    6.3|          24.7| 2023-05-23|  2023-12-09|            3.6|    Sandy|\n",
      "|Rajasthan|     Rice|        449.2|            17.4|    5.6|          30.8| 2023-05-11|  2023-07-26|            3.3|     Clay|\n",
      "|  Haryana|     Rice|        592.8|            35.0|    6.2|          20.3| 2023-06-02|  2023-11-11|            4.2|    Loamy|\n",
      "|Rajasthan|    Wheat|        340.9|            29.2|    6.2|          28.5| 2023-04-10|  2023-10-20|            5.3|     Clay|\n",
      "|  Haryana|     Rice|        604.6|            33.2|    5.9|          52.2| 2023-06-25|  2023-12-21|            5.0|    Sandy|\n",
      "|  Haryana|     Rice|        480.6|            32.9|    6.5|          30.0| 2023-04-06|  2023-10-01|            5.0|    Loamy|\n",
      "|Rajasthan|    Maize|        592.4|            23.6|    7.1|          49.6| 2023-05-26|  2023-10-05|            4.8|     Clay|\n",
      "|  Haryana|     Rice|        690.4|            28.7|    6.8|          41.4| 2023-02-13|  2023-08-17|            3.3|    Loamy|\n",
      "|Rajasthan|     Rice|        277.4|            34.7|    6.6|          30.3| 2023-02-09|  2023-09-23|            1.8|     Clay|\n",
      "|   Punjab|    Maize|        562.6|            25.7|    5.5|          47.5| 2023-05-12|  2023-09-28|            1.6|    Sandy|\n",
      "|Rajasthan|    Wheat|        467.6|            30.1|    6.4|          43.5| 2023-06-08|  2023-08-09|            3.4|     Clay|\n",
      "|Rajasthan|    Maize|        667.9|            25.1|    7.1|          52.5| 2023-04-01|  2023-12-28|            1.5|    Sandy|\n",
      "|  Haryana|    Maize|        779.9|            34.0|    6.2|          28.0| 2023-03-09|  2023-10-21|            3.0|    Loamy|\n",
      "|  Haryana|    Maize|        563.5|            15.0|    7.1|          25.9| 2023-05-05|  2023-12-01|            5.1|    Sandy|\n",
      "|  Haryana|    Maize|        688.9|            32.1|    7.2|          39.8| 2023-05-13|  2023-12-24|            1.9|     Clay|\n",
      "|  Haryana|     Rice|        394.3|            20.8|    7.1|          22.8| 2023-06-12|  2023-09-17|            2.0|     Clay|\n",
      "+---------+---------+-------------+----------------+-------+--------------+-----------+------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = spark.read.csv(\"./synthetic_crop_yield_dataset.csv\", header=True, inferSchema=True)\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc6fac03-584e-4444-89f6-43a0e20437ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "state_indexer = StringIndexer(inputCol=\"Region\", outputCol=\"state_index\")\n",
    "data = state_indexer.fit(data).transform(data)\n",
    "\n",
    "crop_indexer = StringIndexer(inputCol=\"Crop Type\", outputCol=\"crop_index\")\n",
    "data = crop_indexer.fit(data).transform(data)\n",
    "\n",
    "soil_indexer = StringIndexer(inputCol=\"Soil Type\", outputCol=\"soil_index\")\n",
    "data = soil_indexer.fit(data).transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11400fb5-b135-4982-8ad9-a8c5d962059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, floor\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Convert label column to integer by flooring values (or round/mapping)\n",
    "\n",
    "# Ensure indices are integers\n",
    "data = data.withColumn(\"state_index\", floor(col(\"state_index\")))\n",
    "data = data.withColumn(\"crop_index\", floor(col(\"crop_index\")))\n",
    "data = data.withColumn(\"soil_index\", floor(col(\"soil_index\")))\n",
    "\n",
    "#data = data.withColumn(\"label\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d701ddf-ddbf-492b-a4b8-85344666c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_columns = [\"state_index\", \"crop_index\", \"Rainfall (mm)\", \"Temperature (°C)\", \"Soil pH\", \"Nitrogen (ppm)\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(data).select(\"features\", \"Yield (tons/ha)\")\n",
    "\n",
    "data = data.withColumn(\"Yield (tons/ha)\", col(\"Yield (tons/ha)\").cast(IntegerType()))\n",
    "#data = data.withColumn(\"features\", col(\"features\").cast(IntegerType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b203fd8-21d4-419a-bd90-d8802c2dfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Yield (tons/ha): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "848ec024-9389-42f7-8880-33fc1a26117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Yield (tons/ha)\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "312b1056-645a-4cfd-98ef-8778101a5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8a1ab5d-3163-4f31-a4a1-36a8a846f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,0.0,277.4,34...|\n",
      "|[1.0,2.0,563.5,15...|\n",
      "|[2.0,0.0,674.8,24...|\n",
      "|[1.0,2.0,779.9,34...|\n",
      "|[1.0,0.0,231.3,26...|\n",
      "|[2.0,0.0,657.4,34...|\n",
      "|[2.0,0.0,244.9,29...|\n",
      "|[0.0,1.0,261.0,25...|\n",
      "|[0.0,2.0,667.9,25...|\n",
      "|[2.0,1.0,763.3,33...|\n",
      "|[0.0,2.0,358.2,31...|\n",
      "|[0.0,0.0,435.7,33...|\n",
      "|[0.0,0.0,610.5,34...|\n",
      "|[1.0,0.0,604.7,15...|\n",
      "|[1.0,1.0,440.8,26...|\n",
      "|[2.0,1.0,401.3,20...|\n",
      "|[0.0,0.0,449.2,17...|\n",
      "|[0.0,1.0,586.6,20...|\n",
      "|[1.0,0.0,394.3,20...|\n",
      "|[1.0,2.0,372.4,17...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+\n",
      "|Yield (tons/ha)|\n",
      "+---------------+\n",
      "|              1|\n",
      "|              3|\n",
      "|              2|\n",
      "|              4|\n",
      "|              4|\n",
      "|              3|\n",
      "|              4|\n",
      "|              4|\n",
      "|              2|\n",
      "|              3|\n",
      "|              4|\n",
      "|              5|\n",
      "|              5|\n",
      "|              3|\n",
      "|              3|\n",
      "|              2|\n",
      "|              1|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select(\"features\").distinct().show()\n",
    "test_data.select(\"Yield (tons/ha)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54717e9c-aa59-417b-9381-71932ac70e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/spark-3.5.4-bin-hadoop3/jars/spark-core_2.12-3.5.4.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------------------+\n",
      "|            features|Yield (tons/ha)|        prediction|\n",
      "+--------------------+---------------+------------------+\n",
      "|[0.0,0.0,318.9,17...|              1| 2.199305194805195|\n",
      "|[0.0,0.0,503.7,31...|              3| 2.666708754208754|\n",
      "|[0.0,0.0,581.3,19...|              2|2.6546079192546586|\n",
      "|[0.0,1.0,207.6,29...|              4|2.7465778403009393|\n",
      "|[0.0,1.0,430.1,25...|              4| 2.947558361626729|\n",
      "|[0.0,1.0,467.6,30...|              3| 3.271849758212176|\n",
      "|[0.0,2.0,232.8,18...|              4| 2.750934099955772|\n",
      "|[0.0,2.0,592.4,23...|              4| 2.386565054883742|\n",
      "|[1.0,0.0,399.7,31...|              2|3.3258759037211716|\n",
      "|[1.0,0.0,400.0,17...|              3| 2.698248196248196|\n",
      "|[1.0,0.0,407.5,30...|              4| 2.660665094277899|\n",
      "|[1.0,0.0,480.6,32...|              5|2.8392094135207477|\n",
      "|[1.0,0.0,604.6,33...|              5|2.7432912153742888|\n",
      "|[1.0,0.0,726.5,32...|              3| 3.084225700338505|\n",
      "|[1.0,1.0,402.8,28...|              3|2.7705113843271745|\n",
      "|[1.0,2.0,422.7,22...|              2|2.8756430714806003|\n",
      "|[2.0,0.0,337.4,20...|              1| 2.525079365079365|\n",
      "+--------------------+---------------+------------------+\n",
      "\n",
      "Model saved successfully at /home/abhay/Spark_dir/Research_Project/models/random_forest_model\n",
      "Root Mean Squared Error (RMSE) on test data: 1.2235631352966954\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='Yield (tons/ha)')\n",
    "\n",
    "# Train the model\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "predictions.show()\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"/home/abhay/Spark_dir/Research_Project/models/random_forest_model\"\n",
    "model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved successfully at {model_path}\")\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f1d6e52-96aa-47fd-a1b5-3b8ac5f4238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and evaluate models\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# evaluator2 = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# results = {}\n",
    "# for name, model in models.items():\n",
    "#     # Train the model\n",
    "#     trained_model = model.fit(train_data)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = trained_model.transform(test_data)\n",
    "#     predictions.show(5)\n",
    "#     # Evaluate accuracy\n",
    "    \n",
    "\n",
    "#     #evaluator = RegressionEvaluator(labelCol=\"Yield (tons/ha)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "#     rmse = evaluator2.evaluate(predictions)\n",
    "#     print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n",
    "#     accuracy = evaluator.evaluate(predictions)\n",
    "#     results[name] = accuracy\n",
    "#     print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86d879fe-c68f-4ec6-98cb-0604d15df201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print(\"\\nModel Performance Comparison:\")\n",
    "# for name, accuracy in sorted_results:\n",
    "#     print(f\"{name}: {accuracy:.2f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7dc3-f71d-4c9a-8823-41e503a94a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5909ca-d2bc-4541-a408-39e53b4bd605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
